# -*- coding: utf-8 -*-
"""Assignment1(NN & DL).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11VOBAI1oeJSMKIsVlYO7SzRJca-q3KRW

# Sravya Somala (C0907007)
"""

# import necessary libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# load the dataset
df= pd.read_csv('Algerian_forest_fires_cleaned.csv')
df

df.head()  # first 5 rows

df.info()  # information about the dataset

df.describe()  # statistical summary of the dataset

df.shape  # shape of the dataset

"""# Data preprocessing"""

# check for null values
df.isnull().sum()

# check for duplicate values
df.duplicated().sum()

# column class is of type object, convert that into numeric
# Check the unique values in 'Classes' column
df['Classes'].unique()

# remove the spaces
df['Classes']= df['Classes'].str.strip()  # strip() is used to remove the spaces
df['Classes'].unique()

# initialize the label encoder
from sklearn.preprocessing import LabelEncoder
le= LabelEncoder()

# fit and transform the classes column to numeric
df['Classes']= le.fit_transform(df['Classes'])
df['Classes'].unique()

df['Classes'].value_counts()

df['year'].value_counts()

df=df.drop('year', axis=1)

# Verify the transformation
df.head()

"""# EDA"""

# calculate the crrelation between all features
plt.figure(figsize=(15,8))
sns.heatmap(df.corr(), annot=True)

# Box plot
plt.figure(figsize=(15,8))
sns.boxplot(data=df)

# density plot for all features
plt.style.use('seaborn')
df.hist(bins=50,figsize=(20,15))
plt.show()

"""# Split the dataset

"""

# Define input and output variables
X = df.drop('FWI', axis=1)  # Input variables (features)
y = df['FWI']  # Output variable (target)

# split the dataset into training and testing
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

X_train.shape, X_test.shape

"""# Feature scaling and standardization

# Multi collinearity
"""

import pandas as pd
from statsmodels.stats.outliers_influence import variance_inflation_factor
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler


# Calculate VIF for each feature
def calculate_vif(X):
    vif_data = pd.DataFrame()
    vif_data['Feature'] = X.columns
    vif_data['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]
    return vif_data

initial_vif = calculate_vif(X)
print("Initial VIF:\n", initial_vif)

# Drop the feature with the highest VIF
if not initial_vif.empty:
    max_vif_feature = initial_vif.loc[initial_vif['VIF'].idxmax(), 'Feature']
    X = X.drop(max_vif_feature, axis=1)

updated_vif = calculate_vif(X)
print("Updated VIF after dropping the feature with highest VIF:\n", updated_vif)

"""# Scaling"""

from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

# split the dataset into training and testing
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

X_train.shape, X_test.shape

# Scaling the features
scaler = StandardScaler()
X_train_sc = scaler.fit_transform(X_train)
X_test_sc = scaler.transform(X_test)

# visualize the data before and after scaling
before_scaling_df = pd.DataFrame(X_train, columns=X.columns)
after_scaling_df = pd.DataFrame(X_train_sc, columns=X.columns)

plt.subplots(figsize=(15, 5))
plt.subplot(1, 2, 1)
sns.boxenplot(data=before_scaling_df)
plt.title('X_train Before Scaling')
plt.subplot(1, 2, 2)
sns.boxenplot(data=after_scaling_df)
plt.title('X_train After Scaling')
plt.show()

"""this plot shows two box-plots with the titles of X_train Before Scaling and X_train After Scaling, these boxes show the outcome of different variables before and after scaling. Pair of Box Plots showing the impact of scaling on a data sample.


The 'X_train before scaling' plot showing a wide distribution and scale of values from the variables, that tend to have a negative impact later for many machine learning algorithms.

All the variables are scaled to the same scale after post-scaling as demonstrated in the plot for 'X_train after acaling'

This normalization results in improved functionality of the algorithm as seen by more well-behaved grouping and less deviation in values from feature to feature.

# Multi linear Regression
"""

# Initialize and train the Multilinear Regression model
lr = LinearRegression()
lr.fit(X_train_sc, y_train)  # fit the model on the training data

print(lr.intercept_)  # intercept
print(lr.coef_)  # coefficients

# test the model
y_pred= lr.predict(X_test_sc)
y_pred

# evaluate the model
from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error

print(f'R2 Score: {r2_score(y_test, y_pred)}')
print(f'MAE: {mean_absolute_error(y_test, y_pred)}')  # Mean Absolute Error
print(f'MSE: {mean_squared_error(y_test, y_pred)}')  # Mean Squared Error
print(f'RMSE: {np.sqrt(mean_squared_error(y_test, y_pred))}')  # Root Mean Squared Error

plt.scatter(y_test, y_pred)
plt.xlabel('Actual FWI')
plt.ylabel('Predicted FWI')

"""# RIDGE"""

# Ridge
from sklearn.linear_model import Ridge, Lasso, ElasticNet
rd = Ridge()

rd.fit(X_train_sc, y_train)  # fit the model on the training data

y_pred_rd = rd.predict(X_test_sc)  # predict on the test data

print('Intercepts:', rd.intercept_)  # intercept
print('Coefficients:', rd.coef_)  # coefficients
print(f'R2 Score: {r2_score(y_test, y_pred_rd)}')  # R2 Score
print(f'MAE: {mean_absolute_error(y_test, y_pred_rd)}')  # Mean Absolute Error
print(f'MSE: {mean_squared_error(y_test, y_pred_rd)}')  # Mean Squared Error
print(f'RMSE: {np.sqrt(mean_squared_error(y_test, y_pred_rd))}')  # Root Mean Squared Error

plt.scatter(y_test, y_pred_rd)
plt.xlabel('Actual FWI')
plt.ylabel('Predicted FWI')

"""# LASSO"""

# Lasso
ls = Lasso()  # create the model

ls.fit(X_train_sc, y_train)  # fit the model on the training data

y_pred_ls = ls.predict(X_test_sc)  # predict on the test data

print('intercept:', ls.intercept_)  # intercept
print('coefficient:',ls.coef_)  # coefficients

print(f'R2 Score: {r2_score(y_test, y_pred_ls)}')  # R2 Score
print(f'MAE: {mean_absolute_error(y_test, y_pred_ls)}')  # Mean Absolute Error
print(f'MSE: {mean_squared_error(y_test, y_pred_ls)}')  # Mean Squared Error
print(f'RMSE: {np.sqrt(mean_squared_error(y_test, y_pred_ls))}')  # Root Mean Squared Error

plt.scatter(y_test, y_pred_ls)
plt.xlabel('Actual FWI')
plt.ylabel('Predicted FWI')

"""# Elastic Net"""

# Elastic Net
en = ElasticNet()  # create the model

en.fit(X_train_sc, y_train)  # fit the model on the training data

y_pred_en = en.predict(X_test_sc)  # predict on the test data

print('intercept:', en.intercept_)  # intercept
print('coefficient:', en.coef_)  # coefficients

print(f'R2 Score: {r2_score(y_test, y_pred_en)}')  # R2 Score
print(f'MAE: {mean_absolute_error(y_test, y_pred_en)}')  # Mean Absolute Error
print(f'MSE: {mean_squared_error(y_test, y_pred_en)}')  # Mean Squared Error
print(f'RMSE: {np.sqrt(mean_squared_error(y_test, y_pred_en))}')  # Root Mean Squared Error

plt.scatter(y_test, y_pred_en)
plt.xlabel('Actual FWI')
plt.ylabel('Predicted FWI')

"""# Polynomial Regression"""

# polynomial regression
from sklearn.preprocessing import PolynomialFeatures
from sklearn.pipeline import make_pipeline

# Creating a pipeline for scaling, polynomial feature transformation, and regression
model = make_pipeline(StandardScaler(), PolynomialFeatures(degree=2), LinearRegression())

# Fitting the model
model.fit(X_train, y_train)

X_train.columns, X_test.columns

# shape
X_train.shape, X_test.shape  # original shape

# predict
y_pred_poly = model.predict(X_test)  # predict on the test data
y_pred_poly

print(model.named_steps['linearregression'].intercept_)  # intercept
print(model.named_steps['linearregression'].coef_)  # coefficients

print(f'R2 Score: {r2_score(y_test, y_pred_poly)}')  # R2 Score
print(f'MAE: {mean_absolute_error(y_test, y_pred_poly)}')  # Mean Absolute Error
print(f'MSE: {mean_squared_error(y_test, y_pred_poly)}')  # Mean Squared Error
print(f'RMSE: {np.sqrt(mean_squared_error(y_test, y_pred_poly))}')  # Root Mean Squared Error

plt.scatter(y_test, y_pred_poly)
plt.xlabel('Actual FWI')
plt.ylabel('Predicted FWI')

"""# Hyperparameter tuning and cross validation"""

from sklearn.linear_model import LassoCV, RidgeCV, ElasticNetCV, LinearRegression
from sklearn.metrics import mean_absolute_error, r2_score

# Initialize models
lasso_cv = LassoCV(cv=5, random_state=42)
ridge_cv = RidgeCV(cv=5)
elastic_net_cv = ElasticNetCV(cv=5, random_state=42)
linear_reg = LinearRegression()

# Function to fit and evaluate models
def fit_evaluate(model, name):
    model.fit(X_train_sc, y_train)
    y_pred = model.predict(X_test_sc)
    mae = mean_absolute_error(y_test, y_pred)
    r2 = r2_score(y_test, y_pred) # Use the imported r2_score function
    print(f"{name} - Mean Absolute Error: {mae}, R-squared score: {r2}")  # Print the R-squared score
    if hasattr(model, 'alpha_'):  # Check if the model has an 'alpha_' attribute
        print(f"Best alpha for {name}: {model.alpha_}")  # Print the best alpha value

# Evaluate all models
fit_evaluate(lasso_cv, "Lasso\n")
fit_evaluate(ridge_cv, "Ridge\n")
fit_evaluate(elastic_net_cv, "Elastic Net\n")
fit_evaluate(linear_reg, "Linear Regression\n")

from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import PolynomialFeatures, StandardScaler

# Set up the polynomial regression model
# Adjust the degree of polynomial as needed
degree = 2
poly_model = make_pipeline(StandardScaler(),
                           PolynomialFeatures(degree),
                           LinearRegression())

# Function to fit and evaluate models
def fit_evaluate_poly(model, name):
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    mae = mean_absolute_error(y_test, y_pred)
    r2 = r2_score(y_test, y_pred)
    print(f"{name} - Mean Absolute Error: {mae}, R-squared score: {r2}")

# Evaluate the polynomial model
fit_evaluate_poly(poly_model, f"Polynomial Regression Degree {degree}")

"""summary of the model evaluations:

1. **Polynomial Regression (Degree 2)** had the best accuracy and made the smallest prediction errors.
2. **Linear Regression** was also very accurate, with slightly higher errors than the polynomial model.
3. **Lasso and Elastic Net** models performed well, balancing accuracy with the capability to handle complex data relationships.
4. **Ridge Regression** was somewhat less accurate compared to the other models but still performed decently.

#Result
"""

# difference between actual and predicted values in polynomial
pred_df = pd.DataFrame({'Actual': y_test, 'Predicted': poly_model.predict(X_test)})  # actual vs predicted
pred_df

"""Hence, we observe that polynomial regression with degree 2 has the highest accuracy.

Save and test the polynomial regression model with unseen data

# Decision Tree Regression
"""

# Decision tree
from sklearn.tree import DecisionTreeRegressor
from sklearn.model_selection import GridSearchCV

clf_tree = DecisionTreeRegressor()  # create the model

clf_tree.fit(X_train_sc, y_train)  # fit the model on the training data

# predit and evaluate the model
y_train_pred = clf_tree.predict(X_train_sc)  # predict on the training data
y_train_pred  # predicted values

y_test_pred=clf_tree.predict(X_test_sc)  # predict on the test data
y_test_pred  # predicted values

print(f'Training set R2 Score: {r2_score(y_train, y_train_pred)}')  # R2 Score
print(f'Training set MAE: {mean_absolute_error(y_train, y_train_pred)}')  # Mean Absolute Error
print(f'Training set MSE: {mean_squared_error(y_train, y_train_pred)}')  # Mean Squared Error

print(f'Testing set R2 Score: {r2_score(y_test, y_test_pred)}')  # R2 Score
print(f'Testing set MAE: {mean_absolute_error(y_test, y_test_pred)}')  # Mean Absolute Error
print(f'Testing set MSE: {mean_squared_error(y_test, y_test_pred)}')  # Mean Squared Error

plt.scatter(y_test, y_test_pred)
plt.xlabel('Actual FWI')
plt.ylabel('Predicted FWI')
plt.title('Decision Tree Regressor')
plt.show()

"""# Save the model"""

import pickle
# save the model to disk
poly_model_filename = 'poly_model.pkl'
pickle.dump(poly_model, open(poly_model_filename, 'wb'))  # wb - write binary

linear_reg_filename = 'linear_reg.pkl'
pickle.dump(linear_reg, open(linear_reg_filename, 'wb'))

lasso_cv_filename = 'lasso_cv.pkl'
pickle.dump(lasso_cv, open(lasso_cv_filename, 'wb'))

ridge_cv_filename = 'ridge_cv.pkl'
pickle.dump(ridge_cv, open(ridge_cv_filename, 'wb'))  # wb - write binary

elastic_net_cv_filename = 'elastic_net_cv.pkl'
pickle.dump(elastic_net_cv, open(elastic_net_cv_filename, 'wb'))  # wb - write binary

clf_tree_filename = 'clf_tree.pkl'
pickle.dump(clf_tree, open(clf_tree_filename, 'wb'))  # wb - write binary

"""# load and test the model"""

# model testing
with open('poly_model.pkl', 'rb') as file:
    loaded_poly = pickle.load(file)  # rb - read binary

with open('linear_reg.pkl', 'rb') as file:
    loaded_linear = pickle.load(file)  # rb - read binary

with open('lasso_cv.pkl', 'rb') as file:
    loaded_lasso = pickle.load(file)  # rb - read binary

with open('ridge_cv.pkl', 'rb') as file:
    loaded_ridge = pickle.load(file)  # rb - read binary

with open('elastic_net_cv.pkl', 'rb') as file:
    loaded_elastic = pickle.load(file)  # rb - read binary

with open('clf_tree.pkl', 'rb') as file:
    loaded_tree = pickle.load(file)  # rb - read binary

import pandas as pd

# unseen data
unseen_data = {
     'day': [3],
     'month': [6],
     'Temperature': [22],
     'RH': [40],
     'Ws': [21],
     'Rain': [0],
     'FFMC': [88.2],
     'DMC': [9.9],
     'DC': [30.5],
     'ISI': [6.4],
     'Classes': [0],
     'Region': [1]
 }

# Create a DataFrame from the unseen data
unseen_df = pd.DataFrame(unseen_data)

# Display the DataFrame
unseen_df

unseen_df_sc = scaler.transform(unseen_df)
unseen_df_sc

# predict all models
linear_reg_pred = loaded_linear.predict(unseen_df_sc)  # linear regression
lasso_pred = loaded_lasso.predict(unseen_df_sc)  # lasso
ridge_pred = loaded_ridge.predict(unseen_df_sc)  # ridge
elastic_net_pred = loaded_elastic.predict(unseen_df_sc)  # elastic net
clf_tree_pred = loaded_tree.predict(unseen_df_sc)

print("Linear Regression Prediction:", linear_reg_pred)
print("Lasso Prediction:", lasso_pred)
print("Ridge Prediction:", ridge_pred)
print("Elastic Net Prediction:", elastic_net_pred)
print("Decision Tree Prediction:", clf_tree_pred)

# predicting polynomial model
poly_pred = loaded_poly.predict(unseen_df)
print("Polynomial Regression Prediction:", poly_pred)

